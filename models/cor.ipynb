{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a33571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE_FILE: E:\\git\\phenomics\\barley\\project\\uav\\data\\threeD_dataset_mean.csv\n",
      "TARGET_FILE: E:\\git\\phenomics\\barley\\project\\uav\\data\\agronomic\\Agronomic_data_final.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 文件路径和目标列\n",
    "TARGET_COLUMN = 'GrainYield'\n",
    "FEATURE_FILE = os.path.join(\"E:\\\\\", \"git\", \"phenomics\", \"barley\", \"project\", \"uav\", \"data\", \"threeD_dataset_mean.csv\")\n",
    "TARGET_FILE = r'E:\\git\\phenomics\\barley\\project\\uav\\data\\agronomic\\Agronomic_data_final.xlsx'\n",
    "\n",
    "# 打印路径以调试\n",
    "print(\"FEATURE_FILE:\", FEATURE_FILE)\n",
    "print(\"TARGET_FILE:\", TARGET_FILE)\n",
    "\n",
    "# 检查文件是否存在\n",
    "if not os.path.exists(FEATURE_FILE):\n",
    "    raise FileNotFoundError(f\"Feature file not found: {FEATURE_FILE}\")\n",
    "if not os.path.exists(TARGET_FILE):\n",
    "    raise FileNotFoundError(f\"Target file not found: {TARGET_FILE}\")\n",
    "\n",
    "# 1. 加载数据\n",
    "X = pd.read_csv(FEATURE_FILE)\n",
    "target_df = pd.read_excel(TARGET_FILE)\n",
    "y = target_df[TARGET_COLUMN]\n",
    "\n",
    "# 删除指定行（索引173和218，对应第174和219行）\n",
    "rows_to_drop = [173, 218]\n",
    "X = X.drop(rows_to_drop)\n",
    "y = y.drop(rows_to_drop)\n",
    "\n",
    "# 检查目标变量中是否有0值\n",
    "if 0 in y.values:\n",
    "    print(\"目标变量中存在0值\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "661057c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation matrix shape: (62, 62)\n",
      "\n",
      "Found 124 pairs with correlation > 0.98 or < -0.98:\n",
      "NDVI_mean_msi and MTVI2_mean_msi: 0.9860\n",
      "NDVI_mean_msi and OSAVI_mean_msi: 0.9934\n",
      "NDVI_mean_msi and TVI_mean_msi: 0.9995\n",
      "NDVI_mean_msi and GARI_mean_msi: 0.9973\n",
      "NDVI_mean_msi and NAVI_mean_msi: 0.9964\n",
      "NDVI_mean_msi and RGBVI_mean_msi: 0.9859\n",
      "EVI_mean_msi and SAVI2_mean_msi: 0.9950\n",
      "EVI_mean_msi and EVI2_mean_msi: 0.9948\n",
      "EVI_mean_msi and MSAVI_mean_msi: 0.9947\n",
      "EVI_mean_msi and MTVI2_mean_msi: 0.9907\n",
      "EVI_mean_msi and OSAVI_mean_msi: 0.9885\n",
      "EVI_mean_msi and MCARI1_mean_msi: 0.9921\n",
      "EVI_mean_msi and MCARI2_mean_msi: 0.9980\n",
      "EVI_mean_msi and RDVI_mean_msi: 0.9930\n",
      "EVI_mean_msi and SAVI_mean_msi: 0.9950\n",
      "NDWI_mean_msi and GNDVI_mean_msi: -1.0000\n",
      "NDWI_mean_msi and BNDVI_mean_msi: -0.9872\n",
      "SAVI2_mean_msi and EVI2_mean_msi: 0.9989\n",
      "SAVI2_mean_msi and MSAVI_mean_msi: 0.9979\n",
      "SAVI2_mean_msi and MTVI2_mean_msi: 0.9846\n",
      "SAVI2_mean_msi and OSAVI_mean_msi: 0.9930\n",
      "SAVI2_mean_msi and MCARI1_mean_msi: 0.9919\n",
      "SAVI2_mean_msi and MCARI2_mean_msi: 0.9938\n",
      "SAVI2_mean_msi and RDVI_mean_msi: 0.9997\n",
      "SAVI2_mean_msi and SAVI_mean_msi: 1.0000\n",
      "PSRI_mean_msi and NGRDI_mean_msi: -0.9807\n",
      "PSRI_mean_msi and GRVI_mean_msi: -0.9807\n",
      "PSRI_mean_msi and VARI_mean_msi: -0.9830\n",
      "NDRE_mean_msi and CIredE_mean_msi: 0.9906\n",
      "NDRE_mean_msi and RESAVI_mean_msi: 0.9836\n",
      "NDRE_mean_msi and WDRVI_mean_msi: 0.9817\n",
      "NDRE_mean_msi and GARI_mean_msi: 0.9845\n",
      "NDRE_mean_msi and MSR-REG_mean_msi: 0.9974\n",
      "NDRE_mean_msi and OSAVI-REG_mean_msi: 0.9960\n",
      "NDRE_mean_msi and RDVI-REG_mean_msi: 0.9806\n",
      "NDRE_mean_msi and SR-REG_mean_msi: 0.9906\n",
      "CIredE_mean_msi and RESAVI_mean_msi: 0.9854\n",
      "CIredE_mean_msi and MSR_mean_msi: 0.9817\n",
      "CIredE_mean_msi and MSR-REG_mean_msi: 0.9979\n",
      "CIredE_mean_msi and OSAVI-REG_mean_msi: 0.9918\n",
      "CIredE_mean_msi and RDVI-REG_mean_msi: 0.9838\n",
      "CIredE_mean_msi and SR-REG_mean_msi: 1.0000\n",
      "NGRDI_mean_msi and GRVI_mean_msi: 1.0000\n",
      "NGRDI_mean_msi and VARI_mean_msi: 0.9996\n",
      "EVI2_mean_msi and MSAVI_mean_msi: 0.9995\n",
      "EVI2_mean_msi and OSAVI_mean_msi: 0.9880\n",
      "EVI2_mean_msi and MCARI1_mean_msi: 0.9914\n",
      "EVI2_mean_msi and MCARI2_mean_msi: 0.9949\n",
      "EVI2_mean_msi and RDVI_mean_msi: 0.9986\n",
      "EVI2_mean_msi and SAVI_mean_msi: 0.9989\n",
      "GNDVI_mean_msi and BNDVI_mean_msi: 0.9872\n",
      "MCARI_mean_msi and MCARI2_mean_msi: -0.9824\n",
      "MSAVI_mean_msi and OSAVI_mean_msi: 0.9864\n",
      "MSAVI_mean_msi and MCARI1_mean_msi: 0.9890\n",
      "MSAVI_mean_msi and MCARI2_mean_msi: 0.9956\n",
      "MSAVI_mean_msi and RDVI_mean_msi: 0.9973\n",
      "MSAVI_mean_msi and RDVI-REG_mean_msi: 0.9801\n",
      "MSAVI_mean_msi and SAVI_mean_msi: 0.9979\n",
      "MTVI2_mean_msi and OSAVI_mean_msi: 0.9934\n",
      "MTVI2_mean_msi and TVI_mean_msi: 0.9833\n",
      "MTVI2_mean_msi and GARI_mean_msi: 0.9860\n",
      "MTVI2_mean_msi and MCARI2_mean_msi: 0.9893\n",
      "MTVI2_mean_msi and RDVI_mean_msi: 0.9825\n",
      "MTVI2_mean_msi and RGBVI_mean_msi: 0.9914\n",
      "MTVI2_mean_msi and SAVI_mean_msi: 0.9846\n",
      "OSAVI_mean_msi and TVI_mean_msi: 0.9916\n",
      "OSAVI_mean_msi and GARI_mean_msi: 0.9917\n",
      "OSAVI_mean_msi and MCARI2_mean_msi: 0.9877\n",
      "OSAVI_mean_msi and NAVI_mean_msi: 0.9867\n",
      "OSAVI_mean_msi and RDVI_mean_msi: 0.9930\n",
      "OSAVI_mean_msi and RGBVI_mean_msi: 0.9842\n",
      "OSAVI_mean_msi and SAVI_mean_msi: 0.9930\n",
      "REDVI_mean_msi and Vopt1_mean_msi: -0.9895\n",
      "REDVI_mean_msi and RDVI-REG_mean_msi: 0.9815\n",
      "REDVI_mean_msi and RTVI-CORE_mean_msi: 0.9983\n",
      "RESAVI_mean_msi and WDRVI_mean_msi: 0.9864\n",
      "RESAVI_mean_msi and MSR_mean_msi: 0.9873\n",
      "RESAVI_mean_msi and MSR-REG_mean_msi: 0.9868\n",
      "RESAVI_mean_msi and OSAVI-REG_mean_msi: 0.9957\n",
      "RESAVI_mean_msi and RDVI-REG_mean_msi: 0.9997\n",
      "RESAVI_mean_msi and RTVI-CORE_mean_msi: 0.9867\n",
      "RESAVI_mean_msi and SR-REG_mean_msi: 0.9854\n",
      "TVI_mean_msi and GARI_mean_msi: 0.9952\n",
      "TVI_mean_msi and NAVI_mean_msi: 0.9986\n",
      "TVI_mean_msi and RGBVI_mean_msi: 0.9849\n",
      "Vopt1_mean_msi and RTVI-CORE_mean_msi: -0.9848\n",
      "WDRVI_mean_msi and GARI_mean_msi: 0.9813\n",
      "WDRVI_mean_msi and MCARI2_mean_msi: 0.9804\n",
      "WDRVI_mean_msi and MSR_mean_msi: 0.9991\n",
      "WDRVI_mean_msi and MSR-REG_mean_msi: 0.9829\n",
      "WDRVI_mean_msi and OSAVI-REG_mean_msi: 0.9881\n",
      "WDRVI_mean_msi and RDVI-REG_mean_msi: 0.9847\n",
      "CI-RED_mean_msi and MSR_mean_msi: 0.9816\n",
      "CI-RED_mean_msi and RVI_mean_msi: 1.0000\n",
      "GARI_mean_msi and NAVI_mean_msi: 0.9895\n",
      "GARI_mean_msi and OSAVI-REG_mean_msi: 0.9817\n",
      "GOSAVI_mean_msi and SAVI-GREEN_mean_msi: 0.9808\n",
      "GRVI_mean_msi and VARI_mean_msi: 0.9996\n",
      "MCARI1_mean_msi and MCARI2_mean_msi: 0.9876\n",
      "MCARI1_mean_msi and RDVI_mean_msi: 0.9906\n",
      "MCARI1_mean_msi and SAVI_mean_msi: 0.9919\n",
      "MCARI2_mean_msi and RDVI_mean_msi: 0.9922\n",
      "MCARI2_mean_msi and SAVI_mean_msi: 0.9938\n",
      "MNLI_mean_msi and SAVI-GREEN_mean_msi: 0.9924\n",
      "MSR_mean_msi and MSR-REG_mean_msi: 0.9830\n",
      "MSR_mean_msi and OSAVI-REG_mean_msi: 0.9874\n",
      "MSR_mean_msi and RDVI-REG_mean_msi: 0.9859\n",
      "MSR_mean_msi and RVI_mean_msi: 0.9816\n",
      "MSR_mean_msi and SR-REG_mean_msi: 0.9817\n",
      "MSR-REG_mean_msi and OSAVI-REG_mean_msi: 0.9961\n",
      "MSR-REG_mean_msi and RDVI-REG_mean_msi: 0.9846\n",
      "MSR-REG_mean_msi and SR-REG_mean_msi: 0.9979\n",
      "NAVI_mean_msi and RGBVI_mean_msi: 0.9808\n",
      "OSAVI-REG_mean_msi and RDVI-REG_mean_msi: 0.9938\n",
      "OSAVI-REG_mean_msi and SR-REG_mean_msi: 0.9918\n",
      "RDVI_mean_msi and SAVI_mean_msi: 0.9997\n",
      "RDVI-REG_mean_msi and RTVI-CORE_mean_msi: 0.9896\n",
      "RDVI-REG_mean_msi and SR-REG_mean_msi: 0.9838\n",
      "ExG_mean_rgb and TGI_mean_rgb: 0.9938\n",
      "GCC_mean_rgb and GLI_mean_rgb: 0.9998\n",
      "GCC_mean_rgb and RGBVI_mean_rgb: 0.9913\n",
      "GLI_mean_rgb and RGBVI_mean_rgb: 0.9909\n",
      "VEG_mean_rgb and NGRDI_mean_rgb: 0.9847\n",
      "NGRDI_mean_rgb and MGRVI_mean_rgb: 0.9964\n",
      "Correlation pairs saved to correlation_pairs.txt\n"
     ]
    }
   ],
   "source": [
    "# 2. 计算特征之间的相关性\n",
    "correlation_matrix = X.drop('date', axis=1, errors='ignore').corr()  # errors='ignore' 防止date列不存在时出错\n",
    "print(\"Correlation matrix shape:\", correlation_matrix.shape)\n",
    "\n",
    "# 找出相关性绝对值大于0.98的特征对\n",
    "correlation_pairs = []\n",
    "for i in range(correlation_matrix.shape[0]):\n",
    "    for j in range(i + 1, correlation_matrix.shape[1]):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.98:\n",
    "            correlation_pairs.append((correlation_matrix.columns[i], correlation_matrix.columns[j], correlation_matrix.iloc[i, j]))\n",
    "\n",
    "print(f\"\\nFound {len(correlation_pairs)} pairs with correlation > 0.98 or < -0.98:\")\n",
    "for pair in correlation_pairs:\n",
    "    print(f\"{pair[0]} and {pair[1]}: {pair[2]:.4f}\")\n",
    "\n",
    "# 保存相关性对到文件\n",
    "output_file = \"correlation_pairs.txt\"\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(f\"Found {len(correlation_pairs)} pairs with correlation > 0.98 or < -0.98:\\n\")\n",
    "    for pair in correlation_pairs:\n",
    "        f.write(f\"{pair[0]} and {pair[1]}: {pair[2]:.4f}\\n\")\n",
    "print(f\"Correlation pairs saved to {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "08604169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial high correlation pairs: 66\n",
      "Removing feature: EVI_mean_msi (freq: 8, priority: 0.5, score: 16.0000)\n",
      "Removing feature: OSAVI_mean_msi (freq: 7, priority: 0.5, score: 14.0000)\n",
      "Removing feature: SAVI2_mean_msi (freq: 6, priority: 0.5, score: 12.0000)\n",
      "Removing feature: OSAVI-REG_mean_msi (freq: 6, priority: 0.5, score: 12.0000)\n",
      "Removing feature: EVI2_mean_msi (freq: 5, priority: 0.5, score: 10.0000)\n",
      "Removing feature: RDVI_mean_msi (freq: 4, priority: 0.5, score: 8.0000)\n",
      "Removing feature: TVI_mean_msi (freq: 3, priority: 0.5, score: 6.0000)\n",
      "Removing feature: NDRE_mean_msi (freq: 3, priority: 0.5, score: 6.0000)\n",
      "Removing feature: SAVI_mean_msi (freq: 3, priority: 0.5, score: 6.0000)\n",
      "Removing feature: CIredE_mean_msi (freq: 2, priority: 0.5, score: 4.0000)\n",
      "Removing feature: NGRDI_mean_msi (freq: 2, priority: 0.5, score: 4.0000)\n",
      "Removing feature: GCC_mean_rgb (freq: 2, priority: 0.5, score: 4.0000)\n",
      "Removing feature: GARI_mean_msi (freq: 1, priority: 0.5, score: 2.0000)\n",
      "Removing feature: NAVI_mean_msi (freq: 1, priority: 0.5, score: 2.0000)\n",
      "Removing feature: NDWI_mean_msi (freq: 1, priority: 0.5, score: 2.0000)\n",
      "Removing feature: MSAVI_mean_msi (freq: 1, priority: 0.5, score: 2.0000)\n",
      "Removing feature: MTVI2_mean_msi (freq: 1, priority: 0.5, score: 2.0000)\n",
      "Removing feature: REDVI_mean_msi (freq: 1, priority: 0.5, score: 2.0000)\n",
      "Removing feature: RESAVI_mean_msi (freq: 1, priority: 0.5, score: 2.0000)\n",
      "Removing feature: WDRVI_mean_msi (freq: 1, priority: 0.5, score: 2.0000)\n",
      "Removing feature: CI-RED_mean_msi (freq: 1, priority: 0.5, score: 2.0000)\n",
      "Removing feature: GRVI_mean_msi (freq: 1, priority: 0.5, score: 2.0000)\n",
      "Removing feature: MNLI_mean_msi (freq: 1, priority: 0.5, score: 2.0000)\n",
      "Removing feature: MSR-REG_mean_msi (freq: 1, priority: 0.5, score: 2.0000)\n",
      "Removing feature: ExG_mean_rgb (freq: 1, priority: 0.5, score: 2.0000)\n",
      "Removing feature: GLI_mean_rgb (freq: 1, priority: 0.5, score: 2.0000)\n",
      "Removing feature: NGRDI_mean_rgb (freq: 1, priority: 0.5, score: 2.0000)\n",
      "\n",
      "Features to drop: ['CIredE_mean_msi', 'SAVI2_mean_msi', 'GLI_mean_rgb', 'GCC_mean_rgb', 'OSAVI-REG_mean_msi', 'NGRDI_mean_msi', 'CI-RED_mean_msi', 'NAVI_mean_msi', 'OSAVI_mean_msi', 'REDVI_mean_msi', 'WDRVI_mean_msi', 'MTVI2_mean_msi', 'MSR-REG_mean_msi', 'EVI_mean_msi', 'NDRE_mean_msi', 'TVI_mean_msi', 'SAVI_mean_msi', 'GARI_mean_msi', 'RESAVI_mean_msi', 'MNLI_mean_msi', 'ExG_mean_rgb', 'NGRDI_mean_rgb', 'NDWI_mean_msi', 'RDVI_mean_msi', 'MSAVI_mean_msi', 'GRVI_mean_msi', 'EVI2_mean_msi']\n",
      "Features to keep: {'SAVI-GREEN_mean_msi', 'RVI_mean_msi', 'NDVI_mean_msi', 'MGRVI_mean_rgb', 'MCARI2_mean_msi', 'RTVI-CORE_mean_msi', 'VARI_mean_msi', 'MSR_mean_msi', 'RGBVI_mean_msi', 'SR-REG_mean_msi', 'TGI_mean_rgb', 'RGBVI_mean_rgb', 'MCARI1_mean_msi', 'RDVI-REG_mean_msi', 'GNDVI_mean_msi'}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# 设置优先级\n",
    "feature_priorities = {'NDVI_mean_msi': 5.0}\n",
    "\n",
    "def remove_highly_correlated_features(correlation_pairs, threshold, feature_priorities=None):\n",
    "    if feature_priorities is None:\n",
    "        feature_priorities = {}\n",
    "    \n",
    "    # 筛选高相关性对\n",
    "    high_corr_pairs = [(pair[0], pair[1], pair[2]) for pair in correlation_pairs if abs(pair[2]) > threshold]\n",
    "    if not high_corr_pairs:\n",
    "        print(\"No feature pairs with correlation above the threshold.\")\n",
    "        return [], set()\n",
    "\n",
    "    # 统计特征出现频率\n",
    "    feature_freq = defaultdict(int)\n",
    "    for f1, f2, _ in high_corr_pairs:\n",
    "        feature_freq[f1] += 1\n",
    "        feature_freq[f2] += 1\n",
    "\n",
    "    all_features = set(feature_freq.keys())\n",
    "    features_to_drop = set()\n",
    "\n",
    "    # 调试：打印初始的高相关性对\n",
    "    print(\"Initial high correlation pairs:\", len(high_corr_pairs))\n",
    "\n",
    "    while high_corr_pairs:\n",
    "        max_score = -1\n",
    "        feature_to_remove = None\n",
    "        for feature in feature_freq:\n",
    "            if feature in features_to_drop:\n",
    "                continue\n",
    "            freq = feature_freq[feature]\n",
    "            priority = feature_priorities.get(feature, 0.5)\n",
    "            score = freq / (priority + 1e-6)\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                feature_to_remove = feature\n",
    "        \n",
    "        if feature_to_remove is None:\n",
    "            print(\"No feature to remove, breaking loop.\")\n",
    "            break\n",
    "        \n",
    "        features_to_drop.add(feature_to_remove)\n",
    "        print(f\"Removing feature: {feature_to_remove} (freq: {feature_freq[feature_to_remove]}, priority: {priority}, score: {max_score:.4f})\")\n",
    "        \n",
    "        # 更新高相关性对\n",
    "        new_high_corr_pairs = [(f1, f2, corr) for f1, f2, corr in high_corr_pairs \n",
    "                               if f1 != feature_to_remove and f2 != feature_to_remove]\n",
    "        high_corr_pairs = new_high_corr_pairs\n",
    "        \n",
    "        # 更新频率\n",
    "        feature_freq = defaultdict(int)\n",
    "        for f1, f2, _ in high_corr_pairs:\n",
    "            feature_freq[f1] += 1\n",
    "            feature_freq[f2] += 1\n",
    "\n",
    "    features_to_keep = all_features - features_to_drop\n",
    "    return list(features_to_drop), features_to_keep\n",
    "# 假设 correlation_pairs 已正确定义，例如从前面的代码生成\n",
    "# correlation_pairs = [('feat1', 'feat2', 0.99), ('feat2', 'feat3', 0.995), ...]\n",
    "# 运行特征移除算法\n",
    "features_to_drop, features_to_keep = remove_highly_correlated_features(\n",
    "    correlation_pairs, threshold=0.99, feature_priorities=feature_priorities\n",
    ")\n",
    "print(\"\\nFeatures to drop:\", features_to_drop)\n",
    "print(\"Features to keep:\", features_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c13fd578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining features after correlation filtering: 15\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1150, 286]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m X \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(scaler\u001b[38;5;241m.\u001b[39mfit_transform(X), columns\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# 6. 数据分割\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# 7. 定义和训练多个模型\u001b[39;00m\n\u001b[0;32m     16\u001b[0m models \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLinear Regression\u001b[39m\u001b[38;5;124m\"\u001b[39m: LinearRegression(),\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVR\u001b[39m\u001b[38;5;124m\"\u001b[39m: SVR(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeural Network\u001b[39m\u001b[38;5;124m\"\u001b[39m: MLPRegressor(hidden_layer_sizes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m200\u001b[39m,), max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     22\u001b[0m }\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\torch\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\torch\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2848\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2845\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2846\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2848\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2850\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   2851\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2852\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m   2853\u001b[0m )\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\torch\\lib\\site-packages\\sklearn\\utils\\validation.py:532\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \n\u001b[0;32m    504\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;124;03m[[1, 2, 3], array([2, 3, 4]), None, <...Sparse...dtype 'int64'...shape (3, 1)>]\u001b[39;00m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    531\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[1;32m--> 532\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\torch\\lib\\site-packages\\sklearn\\utils\\validation.py:475\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    473\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 475\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    476\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    477\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    478\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1150, 286]"
     ]
    }
   ],
   "source": [
    "# 4. 筛选特征\n",
    "X = X[list(features_to_keep)]\n",
    "print(f\"Remaining features after correlation filtering: {X.shape[1]}\")\n",
    "\n",
    "# 5. 数据预处理\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# 6. 数据分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 7. 定义和训练多个模型\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"SVR\": SVR(kernel='rbf'),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(n_estimators=100, random_state=42),\n",
    "    \"Neural Network\": MLPRegressor(hidden_layer_sizes=(200,), max_iter=500, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    results[name] = {\"MSE\": mse, \"R²\": r2}\n",
    "    print(f\"\\n{name} Performance:\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "    print(f\"R-squared (R²): {r2:.4f}\")\n",
    "\n",
    "# 8. 可视化最佳模型（以XGBoost为例）\n",
    "best_model = models[\"XGBoost\"]\n",
    "y_pred = best_model.predict(X_test)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred, color='blue', alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('XGBoost: True vs Predicted Values')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
